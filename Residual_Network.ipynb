{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras.initializers import glorot_uniform\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageOps\n",
    "import h5py\n",
    "%matplotlib inline\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, stage, block):\n",
    "    \"\"\"\n",
    "    Implementation of the identity block\n",
    "    \n",
    "    Arguments:\n",
    "    X: Input\n",
    "    f: integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters: Number of filters in the CONV layers of the main path\n",
    "    stage: Integer, used to name the layers, depending on their position in the network\n",
    "    block: String, used to name the layers, depending on their position in the network\n",
    "    \n",
    "    Returns:\n",
    "    X: Output of the identity block\n",
    "    \"\"\"\n",
    "    # Defining some name basis\n",
    "    conv_name_base = \"res\" + str(stage) + block + \"_branch\"\n",
    "    bn_name_base = \"bn\" + str(stage) + block + \"_branch\"\n",
    "    \n",
    "    # Retrieve filters\n",
    "    F1, F2, F3, F4 = filters\n",
    "    \n",
    "    # Save the input value, to use it later to add to the main path\n",
    "    X_shortcut = X\n",
    "    \n",
    "    # first component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1, 1), padding = \"valid\", name = conv_name_base + \"2a\",\n",
    "               kernel_initializer = glorot_uniform(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + \"2a\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    # Second component of main path\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1, 1), padding = \"same\", name = conv_name_base + \"2b\",\n",
    "              kernel_initializer = glorot_uniform(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + \"2b\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    # Third component of main path\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1, 1), padding = \"valid\", name = conv_name_base + \"2c\",\n",
    "              kernel_initializer = glorot_uniform(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + \"2c\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    # Fourth component of the main path\n",
    "    X = Conv2D(filters = F4, kernel_size = (f, f), strides = (1, 1), padding = \"same\", name = conv_name_base + \"2d\",\n",
    "              kernel_initializer = glorot_uniform(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + \"2d\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    # Add shortcut to the main path and pass it through a RelU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional block\n",
    "    \n",
    "    Arguments:\n",
    "    X: Input\n",
    "    f: Integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters: filters: Number of filters in the CONV layers of the main path\n",
    "    stage: Integer, used to name the layers, depending on their position in the network\n",
    "    block: String, used to name the layers, depending on their position in the network\n",
    "    s: Integer, specifying the stride to be used\n",
    "    \n",
    "    Returns:\n",
    "    X: Output of the convolutional block\n",
    "    \"\"\"\n",
    "    \n",
    "    # Defining name basis:\n",
    "    conv_name_base =  \"res\" + str(stage) + block + \"_branch\"\n",
    "    bn_name_base = \"bn\" + str(stage) + block + \"_branch\"\n",
    "    \n",
    "    # Retrieve filters\n",
    "    F1, F2, F3, F4 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (s, s), padding = \"valid\", name = conv_name_base + \"2a\",\n",
    "              kernel_initializer = glorot_uniform(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + \"2a\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    # Second component of main path\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1, 1), padding = \"same\", name = conv_name_base + \"2b\",\n",
    "              kernel_initializer = glorot_uniform(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + \"2b\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    #Third component of main path\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (s, s), padding = \"valid\", name = conv_name_base + \"2c\",\n",
    "              kernel_initializer = glorot_uniform(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + \"2c\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    #Fourth component of main path\n",
    "    X = Conv2D(filters = F4, kernel_size = (f, f), strides = (1, 1), padding = \"same\", name = conv_name_base + \"2d\",\n",
    "               kernel_initializer = glorot_uniform(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + \"2d\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    # Shortcut path\n",
    "    X_shortcut = Conv2D(filters = F4, kernel_size = (f, f), strides = (1, 1), padding = \"same\", name = conv_name_base + \"1\",\n",
    "                       kernel_initializer = glorot_uniform(seed = 0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3, name =  bn_name_base + \"1\")(X_shortcut)\n",
    "    \n",
    "    # Add shortcut to the main path and pass it through a RelU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet(input_shape = (512, 512, 3), classes = 1):\n",
    "    \"\"\"\n",
    "    Implementation of a Residual Network with 150 layers\n",
    "    \n",
    "    Inputs:\n",
    "    input_shape: shape of the images\n",
    "    classes: Integer, number of classes\n",
    "    \n",
    "    Returns:\n",
    "    model: a model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input as a tensor\n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    # Zero padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input) \n",
    "    \n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), name = \"conv1\", kernel_initializer=  glorot_uniform(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = \"bn_conv1\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    X = MaxPooling2D((3, 3), strides = (2, 2))(X)\n",
    "    \n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256, 256], stage = 2, block = \"a\", s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256, 256], stage = 2, block = \"b\")\n",
    "    X = identity_block(X, 3, [64, 64, 256, 256], stage = 2, block = \"c\")\n",
    "    \n",
    "    # Stage 3\n",
    "    X = convolutional_block(X, f = 3, filters = [128, 128, 512, 512], stage = 3, block = \"a\", s = 1)\n",
    "    X = identity_block(X, 3, [128, 128, 512, 512], stage = 3, block = \"b\")\n",
    "    X = identity_block(X, 3, [128, 128, 512, 512], stage = 3, block = \"c\")\n",
    "    X = identity_block(X, 3, [128, 128, 512, 512], stage = 3, block = \"d\")\n",
    "    \n",
    "    # Stage 4\n",
    "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024, 1024], stage = 4, block = \"a\", s = 1)\n",
    "    X = identity_block(X, 3, [256, 256, 1024, 1024], stage = 4, block = \"b\")\n",
    "    X = identity_block(X, 3, [256, 256, 1024, 1024], stage = 4, block = \"c\")\n",
    "    X = identity_block(X, 3, [256, 256, 1024, 1024], stage = 4, block = \"d\")\n",
    "    X = identity_block(X, 3, [256, 256, 1024, 1024], stage = 4, block = \"e\")\n",
    "    \n",
    "    # Stage 5\n",
    "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048, 2048], stage = 5, block = \"a\", s = 1)\n",
    "    X = identity_block(X, 3, [512, 512, 2048, 2048], stage = 5, block = \"b\")\n",
    "    X = identity_block(X, 3, [512, 512, 2048, 2048], stage = 5, block = \"c\")\n",
    "    X = identity_block(X, 3, [512, 512, 2048, 2048], stage = 5, block = \"d\")\n",
    "    X = identity_block(X, 3, [512, 512, 2048, 2048], stage = 5, block = \"e\")\n",
    "    X = identity_block(X, 3, [512, 512, 2048, 2048], stage = 5, block = \"f\")\n",
    "    \n",
    "    # Stage 6\n",
    "    X = convolutional_block(X, f = 3, filters = [1024, 1024, 4096, 4096], stage = 6, block = \"a\", s = 1)\n",
    "    X = identity_block(X, 3, [1024, 1024, 4096, 4096], stage = 6, block = \"b\")\n",
    "    X = identity_block(X, 3, [1024, 1024, 4096, 4096], stage = 6, block = \"c\")\n",
    "    X = identity_block(X, 3, [1024, 1024, 4096, 4096], stage = 6, block = \"d\")\n",
    "    \n",
    "    # Average Pool\n",
    "    X = AveragePooling2D(pool_size = (2, 2), padding = \"same\")(X)\n",
    "    \n",
    "    # Output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation = \"sigmoid\", name = \"fc\" + str(classes), kernel_initializer = glorot_uniform(seed = 0))(X)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name = \"ResNet\")\n",
    "    \n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(input_shape = (512, 512, 3), classes = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='logcosh', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_x = pd.read_csv(\"MURA-v1.1/train_image_paths.csv\")\n",
    "train_data_y = pd.read_csv(\"MURA-v1.1/train_labeled_studies.csv\")\n",
    "valid_data_x = pd.read_csv(\"MURA-v1.1/valid_image_paths.csv\")\n",
    "valid_data_y = pd.read_csv(\"MURA-v1.1/valid_labeled_studies.csv\")\n",
    "train_x_orig = train_data_x.iloc[:, 0]\n",
    "train_y_orig = train_data_y.iloc[:, 1]\n",
    "valid_x_orig = valid_data_x.iloc[:, 0]\n",
    "valid_y_orig = valid_data_y.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_array = []\n",
    "desired_size = 512\n",
    "\n",
    "for i in range (len(train_x_orig)):\n",
    "    # Convet images from grayscale to RGB\n",
    "    image = Image.open(train_x_orig.iloc[i])\n",
    "    image = image.convert(\"RGB\")\n",
    "    \n",
    "    # Resize image so every image got the same shape\n",
    "    old_size = image.size  # old_size[0] is in (width, height) format\n",
    "    ratio = float(desired_size)/max(old_size)\n",
    "    new_size = tuple([int(x*ratio) for x in old_size])\n",
    "    \n",
    "    # Use thumbnail() or resize() method to resize the input image  \n",
    "    image = image.resize(new_size, Image.ANTIALIAS)\n",
    "    \n",
    "    # Create a new image and paste the resized on it\n",
    "    new_image = Image.new(\"RGB\", (desired_size, desired_size))\n",
    "    new_image.paste(image, ((desired_size-new_size[0])//2,\n",
    "                    (desired_size-new_size[1])//2))\n",
    "\n",
    "    array = np.array(new_image)\n",
    "    \n",
    "    #Test the dimensions of the data\n",
    "    print(\"Shape = \" + str(array.shape) + \" \" + str(i))\n",
    "    \n",
    "    train_data_array.append(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do it twice, once for training data and another one for validation data\n",
    "valid_data_array = []\n",
    "desired_size = 512\n",
    "\n",
    "for i in range (len(valid_x_orig)):\n",
    "    image = Image.open(valid_x_orig.iloc[i])\n",
    "    image = image.convert(\"RGB\")\n",
    "    \n",
    "    old_size = image.size  \n",
    "    ratio = float(desired_size)/max(old_size)\n",
    "    new_size = tuple([int(x*ratio) for x in old_size])\n",
    "   \n",
    "    image = image.resize(new_size, Image.ANTIALIAS)\n",
    "    \n",
    "    new_image = Image.new(\"RGB\", (desired_size, desired_size))\n",
    "    new_image.paste(image, ((desired_size-new_size[0])//2,\n",
    "                    (desired_size-new_size[1])//2))\n",
    "\n",
    "    array = np.array(new_image)\n",
    "    \n",
    "    print(\"Shape = \" + str(array.shape) + \" \" + str(i))\n",
    "    \n",
    "    valid_data_array.append(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack all the images\n",
    "train_data = np.stack(train_data_array, axis = 0)\n",
    "valid_data = np.stack(valid_data_array, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize image vectors\n",
    "X_train = train_data/255\n",
    "X_valid = valid_data/255\n",
    "Y_train = train_y_orig\n",
    "Y_valid = valid_y_orig\n",
    "print(\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print(\"number of test examples = \" + str(X_valid.shape[0]))\n",
    "print(\"X_train shape: \" + str(X_train.shape))\n",
    "print(\"Y_train shape: \" + str(Y_train.shape))\n",
    "print(\"X_test shape: \" + str(X_valid.shape))\n",
    "print(\"Y_test shape: \" + str(Y_valid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "model.fit(X_train, Y_train, epochs = 3, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.evaluate(X_valid, Y_valid)\n",
    "print(\"Loss = \" + str(preds[0]))\n",
    "print(\"Test Accuracy = \" + str(preds[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
